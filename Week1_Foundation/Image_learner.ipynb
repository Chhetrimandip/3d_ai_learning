{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZMA3EtMasoJ"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.optim as optim\n",
        "# from PIL import Image\n",
        "# from torchvision.transforms import ToTensor, ToPILImage\n",
        "# import numpy as np\n",
        "\n",
        "# # --- 1. Configuration ---\n",
        "# IMAGE_PATH = 'target.jpg'  # Put a small image here (e.g., 128x128)\n",
        "# STEPS = 5000\n",
        "# LR = 1e-3\n",
        "# HIDDEN_SIZE = 256\n",
        "# LAYERS = 4\n",
        "\n",
        "# # --- 2. Data Preparation ---\n",
        "# def get_image_data(path):\n",
        "#     img = Image.open(path).convert('RGB')\n",
        "#     # Resize to something small for speed if needed\n",
        "#     img = img.resize((128, 128))\n",
        "#     tensor_img = ToTensor()(img) # Shape: [3, H, W]\n",
        "#     return tensor_img\n",
        "\n",
        "# target_img = get_image_data(IMAGE_PATH)\n",
        "# c, h, w = target_img.shape\n",
        "\n",
        "# # Create Coordinate Grid (Inputs: x, y)\n",
        "# # We map coordinates to range [-1, 1] for better training stability\n",
        "# x_coords = torch.linspace(-1, 1, w)\n",
        "# y_coords = torch.linspace(-1, 1, h)\n",
        "# grid_y, grid_x = torch.meshgrid(y_coords, x_coords, indexing='ij')\n",
        "\n",
        "# # Flatten inputs and targets\n",
        "# # Inputs: [H*W, 2] -> (x, y) for every pixel\n",
        "# inputs = torch.stack([grid_x, grid_y], dim=-1).reshape(-1, 2)\n",
        "# # Targets: [H*W, 3] -> (r, g, b) for every pixel\n",
        "# targets = target_img.permute(1, 2, 0).reshape(-1, 3)\n",
        "\n",
        "# # --- 3. The Model (MLP) ---\n",
        "# class NeuralPainter(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         layers = []\n",
        "#         # Input is 2 (x, y)\n",
        "#         layers.append(nn.Linear(2, HIDDEN_SIZE))\n",
        "#         layers.append(nn.ReLU())\n",
        "\n",
        "#         for _ in range(LAYERS):\n",
        "#             layers.append(nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE))\n",
        "#             layers.append(nn.ReLU())\n",
        "\n",
        "#         # Output is 3 (r, g, b)\n",
        "#         layers.append(nn.Linear(HIDDEN_SIZE, 3))\n",
        "#         layers.append(nn.Sigmoid()) # Forces output to be between 0 and 1 (valid colors)\n",
        "\n",
        "#         self.net = nn.Sequential(*layers)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         return self.net(x)\n",
        "\n",
        "# model = NeuralPainter()\n",
        "# optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "# criterion = nn.MSELoss()\n",
        "\n",
        "# # --- 4. Training ---\n",
        "# print(f\"Training on {h}x{w} image...\")\n",
        "\n",
        "# for step in range(STEPS):\n",
        "#     optimizer.zero_grad()\n",
        "\n",
        "#     # Predict colors for all coordinates\n",
        "#     outputs = model(inputs)\n",
        "\n",
        "#     # Calculate loss against actual pixel colors\n",
        "#     loss = criterion(outputs, targets)\n",
        "\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "\n",
        "#     if step % 500 == 0:\n",
        "#         print(f\"Step {step}, Loss: {loss.item():.6f}\")\n",
        "\n",
        "# # --- 5. Visualization ---\n",
        "# with torch.no_grad():\n",
        "#     predicted_pixels = model(inputs)\n",
        "#     # Reshape back to image format [C, H, W]\n",
        "#     reconstructed = predicted_pixels.reshape(h, w, 3).permute(2, 0, 1)\n",
        "\n",
        "#     # Save result\n",
        "#     ToPILImage()(reconstructed).save('day9_result.png')\n",
        "#     print(\"Saved reconstruction to 'day9_result.png'\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "from torchvision.transforms import ToTensor\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/pytorch/hub/master/images/dog.jpg\"\n",
        "response = requests.get(url)\n",
        "img = Image.open(BytesIO(response.content))\n",
        "#resizing to 100x100\n",
        "img = img.resize((100,100))\n",
        "\n",
        "#2 Convert to numbers( tensor )\n",
        "target_tensor = ToTensor()(img)\n",
        "print(\"Success\")\n",
        "print(f\"Image Shape : {target_tensor.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lb10PvU_dHm2",
        "outputId": "2d661b0a-19c0-4a0a-f65d-752858f292ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success\n",
            "Image Shape : torch.Size([3, 100, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c,h,w = target_tensor.shape\n",
        "#getting the dimensions\n",
        "\n",
        "# create the rulers for x and y axis\n",
        "x_axis = torch.linspace(-1,1,w)\n",
        "y_axis = torch.linspace(-1,1,h)\n",
        "\n",
        "grid_y, grid_x = torch.meshgrid(y_axis, x_axis, indexing ='ij' )\n",
        "#4 Combine them into pairs\n",
        "# this Creates a list of pairs : [(-1,-1),(-1,-0.9)....(1,1)]\n",
        "inputs = torch.stack([grid_x,grid_y], dim = -1)\n",
        "\n",
        "#5 Flatten it\n",
        "# tye network expects a long list of points , not a square grid\n",
        "# reshape to {total pixesl m 2}\n",
        "inputs = inputs.reshape(-1,2)\n",
        "print(f\"Inputs shape : {inputs.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oesx5Jv0g2ra",
        "outputId": "98fc8a35-94cd-45d1-e1f3-90020d265c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs shape : torch.Size([10000, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert Image pixels' rgb to tensor of [10000,3]\n",
        "target_flat = target_tensor.permute(1,2,0)\n",
        "# squash 100*100 = 10000\n",
        "target_flat = target_flat.reshape(-1,3)\n",
        "print(f\"Target shape : {target_flat.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_S-4LiWkudgH",
        "outputId": "c8b3450a-23d5-4fbe-9b5d-c3e3b143dca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target shape : torch.Size([10000, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralPainter(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Use HIDDEN_SIZE and LAYERS from the initial setup\n",
        "        hidden_size = 256 # From the initial setup (uZMA3EtMasoJ)\n",
        "        num_layers = 4    # From the initial setup (uZMA3EtMasoJ)\n",
        "\n",
        "        layers = []\n",
        "        # Input is 2 (x, y)\n",
        "        layers.append(nn.Linear(2, hidden_size))\n",
        "        layers.append(nn.ReLU())\n",
        "\n",
        "        for _ in range(num_layers - 1):\n",
        "            layers.append(nn.Linear(hidden_size, hidden_size))\n",
        "            layers.append(nn.ReLU())\n",
        "\n",
        "        # Output is 3 (r, g, b)\n",
        "        layers.append(nn.Linear(hidden_size, 3))\n",
        "        layers.append(nn.Sigmoid()) # Forces output to be between 0 and 1 (valid colors)\n",
        "\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "#Create the robot\n",
        "model = NeuralPainter()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2wOPWOfqb8e",
        "outputId": "876c4b95-9ed8-4585-99ce-1f8e476c07d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralPainter(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=2, out_features=256, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (7): ReLU()\n",
            "    (8): Linear(in_features=256, out_features=3, bias=True)\n",
            "    (9): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.optim is the optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
        "#2 Setup Grading System (loss)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "#train for 2000 steps\n",
        "print(\"training started...\")\n",
        "for step in range(2001):\n",
        "  # A reset Gradients ( standard pytorch boilerplate)\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  #b Ask the students to guess colpurs for all coordinates\n",
        "  guesses = model(inputs)\n",
        "\n",
        "  #c compare guesses to acutal answers\n",
        "  loss = criterion(guesses, target_flat)\n",
        "  # Backpropagation by finding out which neuron made mistakes\n",
        "  loss.backward()\n",
        "  # update weights\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  if step % 10 == 0:\n",
        "    print(f\"step {step} , Error (loss): {loss.item():.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yboIYACKsN7g",
        "outputId": "80ed2f33-ab93-4d7d-f2ed-735f209cca8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training started...\n",
            "step 0 , Error (loss): 0.11023\n",
            "step 10 , Error (loss): 0.08022\n",
            "step 20 , Error (loss): 0.05510\n",
            "step 30 , Error (loss): 0.03340\n",
            "step 40 , Error (loss): 0.02423\n",
            "step 50 , Error (loss): 0.01732\n",
            "step 60 , Error (loss): 0.01476\n",
            "step 70 , Error (loss): 0.01281\n",
            "step 80 , Error (loss): 0.01118\n",
            "step 90 , Error (loss): 0.01005\n",
            "step 100 , Error (loss): 0.00923\n",
            "step 110 , Error (loss): 0.00904\n",
            "step 120 , Error (loss): 0.00831\n",
            "step 130 , Error (loss): 0.00845\n",
            "step 140 , Error (loss): 0.00773\n",
            "step 150 , Error (loss): 0.00743\n",
            "step 160 , Error (loss): 0.00721\n",
            "step 170 , Error (loss): 0.00691\n",
            "step 180 , Error (loss): 0.00667\n",
            "step 190 , Error (loss): 0.00644\n",
            "step 200 , Error (loss): 0.00623\n",
            "step 210 , Error (loss): 0.00604\n",
            "step 220 , Error (loss): 0.00835\n",
            "step 230 , Error (loss): 0.00642\n",
            "step 240 , Error (loss): 0.00574\n",
            "step 250 , Error (loss): 0.00563\n",
            "step 260 , Error (loss): 0.00543\n",
            "step 270 , Error (loss): 0.00528\n",
            "step 280 , Error (loss): 0.00522\n",
            "step 290 , Error (loss): 0.00512\n",
            "step 300 , Error (loss): 0.00502\n",
            "step 310 , Error (loss): 0.00509\n",
            "step 320 , Error (loss): 0.00481\n",
            "step 330 , Error (loss): 0.00470\n",
            "step 340 , Error (loss): 0.00545\n",
            "step 350 , Error (loss): 0.00506\n",
            "step 360 , Error (loss): 0.00483\n",
            "step 370 , Error (loss): 0.00469\n",
            "step 380 , Error (loss): 0.00467\n",
            "step 390 , Error (loss): 0.00435\n",
            "step 400 , Error (loss): 0.00420\n",
            "step 410 , Error (loss): 0.00455\n",
            "step 420 , Error (loss): 0.00433\n",
            "step 430 , Error (loss): 0.00406\n",
            "step 440 , Error (loss): 0.00403\n",
            "step 450 , Error (loss): 0.00392\n",
            "step 460 , Error (loss): 0.00430\n",
            "step 470 , Error (loss): 0.00395\n",
            "step 480 , Error (loss): 0.00382\n",
            "step 490 , Error (loss): 0.00377\n",
            "step 500 , Error (loss): 0.00377\n",
            "step 510 , Error (loss): 0.00369\n",
            "step 520 , Error (loss): 0.00374\n",
            "step 530 , Error (loss): 0.00373\n",
            "step 540 , Error (loss): 0.00368\n",
            "step 550 , Error (loss): 0.00404\n",
            "step 560 , Error (loss): 0.00361\n",
            "step 570 , Error (loss): 0.00358\n",
            "step 580 , Error (loss): 0.00349\n",
            "step 590 , Error (loss): 0.00395\n",
            "step 600 , Error (loss): 0.00356\n",
            "step 610 , Error (loss): 0.00339\n",
            "step 620 , Error (loss): 0.00383\n",
            "step 630 , Error (loss): 0.00338\n",
            "step 640 , Error (loss): 0.00333\n",
            "step 650 , Error (loss): 0.00357\n",
            "step 660 , Error (loss): 0.00335\n",
            "step 670 , Error (loss): 0.00361\n",
            "step 680 , Error (loss): 0.00359\n",
            "step 690 , Error (loss): 0.00341\n",
            "step 700 , Error (loss): 0.00330\n",
            "step 710 , Error (loss): 0.00317\n",
            "step 720 , Error (loss): 0.00343\n",
            "step 730 , Error (loss): 0.00308\n",
            "step 740 , Error (loss): 0.00302\n",
            "step 750 , Error (loss): 0.00300\n",
            "step 760 , Error (loss): 0.00324\n",
            "step 770 , Error (loss): 0.00295\n",
            "step 780 , Error (loss): 0.00440\n",
            "step 790 , Error (loss): 0.00300\n",
            "step 800 , Error (loss): 0.00294\n",
            "step 810 , Error (loss): 0.00306\n",
            "step 820 , Error (loss): 0.00288\n",
            "step 830 , Error (loss): 0.00285\n",
            "step 840 , Error (loss): 0.00295\n",
            "step 850 , Error (loss): 0.00293\n",
            "step 860 , Error (loss): 0.00279\n",
            "step 870 , Error (loss): 0.00277\n",
            "step 880 , Error (loss): 0.00284\n",
            "step 890 , Error (loss): 0.00302\n",
            "step 900 , Error (loss): 0.00274\n",
            "step 910 , Error (loss): 0.00271\n",
            "step 920 , Error (loss): 0.00284\n",
            "step 930 , Error (loss): 0.00285\n",
            "step 940 , Error (loss): 0.00268\n",
            "step 950 , Error (loss): 0.00264\n",
            "step 960 , Error (loss): 0.00266\n",
            "step 970 , Error (loss): 0.00293\n",
            "step 980 , Error (loss): 0.00259\n",
            "step 990 , Error (loss): 0.00339\n",
            "step 1000 , Error (loss): 0.00331\n",
            "step 1010 , Error (loss): 0.00257\n",
            "step 1020 , Error (loss): 0.00282\n",
            "step 1030 , Error (loss): 0.00276\n",
            "step 1040 , Error (loss): 0.00272\n",
            "step 1050 , Error (loss): 0.00253\n",
            "step 1060 , Error (loss): 0.00310\n",
            "step 1070 , Error (loss): 0.00279\n",
            "step 1080 , Error (loss): 0.00282\n",
            "step 1090 , Error (loss): 0.00269\n",
            "step 1100 , Error (loss): 0.00245\n",
            "step 1110 , Error (loss): 0.00244\n",
            "step 1120 , Error (loss): 0.00266\n",
            "step 1130 , Error (loss): 0.00270\n",
            "step 1140 , Error (loss): 0.00244\n",
            "step 1150 , Error (loss): 0.00239\n",
            "step 1160 , Error (loss): 0.00247\n",
            "step 1170 , Error (loss): 0.00235\n",
            "step 1180 , Error (loss): 0.00234\n",
            "step 1190 , Error (loss): 0.00241\n",
            "step 1200 , Error (loss): 0.00251\n",
            "step 1210 , Error (loss): 0.00243\n",
            "step 1220 , Error (loss): 0.00232\n",
            "step 1230 , Error (loss): 0.00230\n",
            "step 1240 , Error (loss): 0.00230\n",
            "step 1250 , Error (loss): 0.00228\n",
            "step 1260 , Error (loss): 0.00232\n",
            "step 1270 , Error (loss): 0.00235\n",
            "step 1280 , Error (loss): 0.00230\n",
            "step 1290 , Error (loss): 0.00240\n",
            "step 1300 , Error (loss): 0.00284\n",
            "step 1310 , Error (loss): 0.00234\n",
            "step 1320 , Error (loss): 0.00242\n",
            "step 1330 , Error (loss): 0.00235\n",
            "step 1340 , Error (loss): 0.00230\n",
            "step 1350 , Error (loss): 0.00222\n",
            "step 1360 , Error (loss): 0.00254\n",
            "step 1370 , Error (loss): 0.00236\n",
            "step 1380 , Error (loss): 0.00219\n",
            "step 1390 , Error (loss): 0.00224\n",
            "step 1400 , Error (loss): 0.00217\n",
            "step 1410 , Error (loss): 0.00285\n",
            "step 1420 , Error (loss): 0.00239\n",
            "step 1430 , Error (loss): 0.00215\n",
            "step 1440 , Error (loss): 0.00214\n",
            "step 1450 , Error (loss): 0.00211\n",
            "step 1460 , Error (loss): 0.00225\n",
            "step 1470 , Error (loss): 0.00218\n",
            "step 1480 , Error (loss): 0.00210\n",
            "step 1490 , Error (loss): 0.00336\n",
            "step 1500 , Error (loss): 0.00214\n",
            "step 1510 , Error (loss): 0.00228\n",
            "step 1520 , Error (loss): 0.00229\n",
            "step 1530 , Error (loss): 0.00209\n",
            "step 1540 , Error (loss): 0.00206\n",
            "step 1550 , Error (loss): 0.00211\n",
            "step 1560 , Error (loss): 0.00209\n",
            "step 1570 , Error (loss): 0.00254\n",
            "step 1580 , Error (loss): 0.00224\n",
            "step 1590 , Error (loss): 0.00204\n",
            "step 1600 , Error (loss): 0.00251\n",
            "step 1610 , Error (loss): 0.00220\n",
            "step 1620 , Error (loss): 0.00201\n",
            "step 1630 , Error (loss): 0.00246\n",
            "step 1640 , Error (loss): 0.00215\n",
            "step 1650 , Error (loss): 0.00201\n",
            "step 1660 , Error (loss): 0.00237\n",
            "step 1670 , Error (loss): 0.00206\n",
            "step 1680 , Error (loss): 0.00212\n",
            "step 1690 , Error (loss): 0.00207\n",
            "step 1700 , Error (loss): 0.00219\n",
            "step 1710 , Error (loss): 0.00200\n",
            "step 1720 , Error (loss): 0.00203\n",
            "step 1730 , Error (loss): 0.00214\n",
            "step 1740 , Error (loss): 0.00200\n",
            "step 1750 , Error (loss): 0.00208\n",
            "step 1760 , Error (loss): 0.00199\n",
            "step 1770 , Error (loss): 0.00197\n",
            "step 1780 , Error (loss): 0.00194\n",
            "step 1790 , Error (loss): 0.00209\n",
            "step 1800 , Error (loss): 0.00193\n",
            "step 1810 , Error (loss): 0.00246\n",
            "step 1820 , Error (loss): 0.00258\n",
            "step 1830 , Error (loss): 0.00195\n",
            "step 1840 , Error (loss): 0.00238\n",
            "step 1850 , Error (loss): 0.00201\n",
            "step 1860 , Error (loss): 0.00196\n",
            "step 1870 , Error (loss): 0.00193\n",
            "step 1880 , Error (loss): 0.00193\n",
            "step 1890 , Error (loss): 0.00211\n",
            "step 1900 , Error (loss): 0.00189\n",
            "step 1910 , Error (loss): 0.00222\n",
            "step 1920 , Error (loss): 0.00194\n",
            "step 1930 , Error (loss): 0.00188\n",
            "step 1940 , Error (loss): 0.00217\n",
            "step 1950 , Error (loss): 0.00188\n",
            "step 1960 , Error (loss): 0.00216\n",
            "step 1970 , Error (loss): 0.00188\n",
            "step 1980 , Error (loss): 0.00233\n",
            "step 1990 , Error (loss): 0.00204\n",
            "step 2000 , Error (loss): 0.00186\n"
          ]
        }
      ]
    }
  ]
}